# Figma Content Scraper

An AI-powered tool that extracts text content from Figma files and analyzes it using Azure OpenAI to provide insights on UX writing, tone consistency, and content patterns.

## What It Does

This tool:
1. **Extracts** all text strings from a Figma file via the Figma API
2. **Analyzes** each string with AI to determine:
   - Category (button, label, placeholder, heading, etc.)
   - Tone (formal, casual, friendly)
   - Purpose (what the text is meant to do)
   - UX patterns (design patterns used)
3. **Detects Issues** automatically:
   - Honorifics (Mr., Mrs., Dr., etc.)
   - Lorem ipsum and placeholder text
   - Spelling errors
   - Long button/navigation text (>3 words)
   - Plural inconsistencies (app vs apps, task vs tasks)
   - Capitalization issues
4. **Generates** color-coded reports:
   - **Excel workbook** with 3 sheets:
     - âš ï¸ Issues Summary (problems only, sorted by severity)
     - ğŸ“‹ Full Content (all text with complete analysis)
     - ğŸ“– Color Legend (severity guide and workflow)
   - CSV and JSON formats for data processing
   - Corpus-level pattern analysis and UX recommendations

## Prerequisites

- **Node.js** 18+ installed
- **Figma account** with API access
- **Azure OpenAI** deployment (GPT-4 or GPT-4o recommended)

## Setup

### 1. Clone and Install

```bash
git clone <your-repo-url>
cd figma-content-scraper
npm install
```

### 2. Get Your Figma Access Token

1. Log in to [Figma](https://figma.com)
2. Go to **Settings** â†’ **Account** â†’ **Personal Access Tokens**
3. Click **Generate new token**
4. Copy the token (starts with `figd_...`)

### 3. Get Your Azure OpenAI Credentials

1. Go to [Azure Portal](https://portal.azure.com)
2. Navigate to your **Azure OpenAI resource**
3. Go to **Keys and Endpoint**
4. Copy:
   - **Endpoint** (e.g., `https://your-resource.cognitiveservices.azure.com/`)
   - **API Key**
5. Note your **Deployment Name** (e.g., `gpt-4o`, `gpt-4`)

### 4. Configure Environment Variables

**ğŸ”’ SECURITY IMPORTANT:** Never commit your `.env` file!

Copy the template and add your credentials:

```bash
cp .env.example .env
```

Then edit `.env` with your actual values:

```bash
# Figma API
FIGMA_ACCESS_TOKEN=figd_YOUR_TOKEN_HERE

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_DEPLOYMENT=gpt-4o
AZURE_OPENAI_API_VERSION=2025-01-01-preview

# Default Figma File (optional)
FIGMA_FILE_KEY=your_default_file_key

# AI Grounding Instructions (optional)
AI_SYSTEM_PROMPT=You are analyzing UI content for a [Your Product] application. Focus on consistency with [Your Design System] principles.
```

**âœ… Security Best Practices:**
- `.env` is already in `.gitignore` to prevent accidental commits
- Use `.env.example` as a template (never contains real credentials)
- Rotate tokens immediately if accidentally exposed
- Enable GitHub Secret Scanning in repository settings
- Never share `.env` file contents in issues or pull requests

### 5. Get Your Figma File Key

From any Figma file URL:
```
https://figma.com/design/fb46HsIOMPb6yiiiFTbyGO/AI-testing
                              ^^^^^^^^^^^^^^^^^^^^
                              This is your file key
```

## Usage

### Basic Usage

Run with a specific Figma file:

```bash
npm start YOUR_FIGMA_FILE_KEY
```

Or use the default from `.env`:

```bash
npm start
```

### What Happens

The scraper will:
1. Fetch the Figma file structure
2. Extract all text content (only nodes with actual text)
3. Analyze each string with Azure OpenAI
4. Detect issues automatically (honorifics, long text, inconsistencies)
5. Generate timestamped output files in `output/`

### Output Files

Three files are created per run:

**Color-Coded Excel** (`output/[FileName]_[Timestamp]_color_coded.xlsx`):
- **Sheet 1: âš ï¸ Issues Summary** - Only items with problems, sorted by severity
  - ğŸ”´ Critical (red): Honorifics that must be removed
  - ğŸŸ¡ High (yellow): Spelling errors, lorem ipsum
  - ğŸ”µ Medium (blue): Placeholder text, long button/navigation text
  - ğŸŸ  Low (orange): Capitalization and plural inconsistencies
- **Sheet 2: ğŸ“‹ Full Content** - All scraped text with complete AI analysis
- **Sheet 3: ğŸ“– Color Legend** - Severity guide and workflow instructions

**CSV Report** (`output/[FileName]_[Timestamp]_content_library.csv`):
```csv
ID,Name,Type,Path,Content,Category,Tone,Purpose
I1:3418...,Label,TEXT,Document > Page 1 > ...,Search resources...,placeholder,friendly,To guide users in searching...
```

**JSON Report** (`output/[FileName]_[Timestamp]_full_report.json`):
```json
{
  "metadata": { "fileName": "...", "totalItems": 104, ... },
  "statistics": { "categoryBreakdown": {...}, "toneDistribution": {...} },
  "patterns": { "commonPhrases": [...], "recommendations": [...] },
  "content": [ ... all analyzed items ... ]
}
```

## Customizing AI Analysis

### Grounding Instructions

Add custom instructions for the AI in `.env`:

```bash
# Brand voice guidelines
AI_SYSTEM_PROMPT=Analyze content for Acme Corp. Our brand voice is friendly, helpful, and conversational. Avoid jargon.

# Design system focus
AI_SYSTEM_PROMPT=Reference Material Design 3 guidelines. Check for consistency with Google's UX writing style guide.

# Accessibility focus
AI_SYSTEM_PROMPT=Prioritize WCAG AA compliance. Flag any text that may be unclear for screen readers or non-technical users.

# Multi-criteria
AI_SYSTEM_PROMPT=Analyze for: 1) Microsoft Fluent Design consistency, 2) Accessibility (WCAG AA), 3) Localization readiness
```

### Rate Limiting

The tool includes a 100ms delay between API calls. Adjust in `src/contentAnalyzer.js`:

```javascript
// Change this value (in milliseconds)
await new Promise(resolve => setTimeout(resolve, 100));
```

## Analyzing Results

### Review Issues in Excel

Open the color-coded Excel file and start with the **âš ï¸ Issues Summary** sheet:
1. Fix ğŸ”´ Critical issues first (honorifics)
2. Address ğŸŸ¡ High priority (spelling, lorem ipsum)
3. Handle ğŸ”µ Medium issues (placeholders, long text)
4. Review ğŸŸ  Low priority (inconsistencies)
5. Use **ğŸ“‹ Full Content** sheet for complete context

### Search for Specific Terms

```bash
# Case-insensitive search in CSV
grep -i "button" output/[filename].csv

# Count occurrences
grep -i "search" output/[filename].csv | wc -l
```

### Open in Spreadsheet

Open the CSV file in Excel, Google Sheets, or Numbers to:
- Sort by Category, Tone, or Purpose
- Filter for specific patterns
- Analyze tone consistency
- Identify content gaps

### Explore JSON for Patterns

The JSON file includes:
- `statistics` - Category and tone breakdown
- `patterns.commonPhrases` - Recurring text patterns
- `patterns.recommendations` - AI-generated UX suggestions
- `patterns.toneIssues` - Inconsistencies detected

## Project Structure

```
figma-content-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ figmaScraper.js          # Fetches and extracts text from Figma
â”‚   â”œâ”€â”€ contentAnalyzer.js       # AI analysis with Azure OpenAI
â”‚   â”œâ”€â”€ contentLibrary.js        # Generates CSV/JSON reports
â”‚   â”œâ”€â”€ colorCodedExcel.js       # Excel generation with issue detection
â”‚   â”œâ”€â”€ htmlScraper.js           # HTML content extraction (optional)
â”‚   â”œâ”€â”€ htmlUpdater.js           # Apply corrections to HTML (optional)
â”‚   â”œâ”€â”€ contentDesignerAgent.js  # AI Foundry agent integration (optional)
â”‚   â””â”€â”€ index.js                 # Main orchestrator
â”œâ”€â”€ output/                       # Generated reports (timestamped)
â”œâ”€â”€ .env                          # Configuration (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Troubleshooting

### "Error: 401 Unauthorized"

- Check your `FIGMA_ACCESS_TOKEN` is correct
- Ensure the token has access to the file (check sharing settings)

### "Error: Azure OpenAI authentication failed"

- Verify your `AZURE_OPENAI_ENDPOINT` uses the correct format:
  - âœ… `https://resource.cognitiveservices.azure.com/`
  - âŒ `https://resource.openai.azure.com/` (AI Foundry endpoint - different auth)
- Confirm `AZURE_OPENAI_API_KEY` is correct
- Check `AZURE_OPENAI_DEPLOYMENT` matches your deployment name exactly

### "No content found"

- The file might not contain any text nodes
- Try a different Figma file with visible text content

### Rate Limiting Errors

- Increase the delay in `contentAnalyzer.js`
- Check your Azure OpenAI quota and usage

## Advanced Usage

### Multiple File Analysis

Create a script to process multiple files:

```bash
#!/bin/bash
files=("file_key_1" "file_key_2" "file_key_3")
for file in "${files[@]}"; do
  npm start "$file"
done
```

### CI/CD Integration

Run as part of your design-to-code pipeline:

```yaml
# .github/workflows/analyze-figma.yml
name: Analyze Figma Content
on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday at 9am
jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm install
      - run: npm start
        env:
          FIGMA_ACCESS_TOKEN: ${{ secrets.FIGMA_TOKEN }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_KEY }}
```

## HTML Content Scraping (Optional)

The feature branch also includes HTML scraping capabilities:

### Scrape HTML Files

```bash
npm run scrape-html path/to/your/file.html
```

This extracts text from HTML elements (headings, paragraphs, buttons, links) and generates a CSV with corrections column.

### Apply Corrections

1. Edit the CSV file and add corrections in the "Corrected Content" column
2. Apply changes back to HTML:

```bash
npm run apply-html path/to/corrections.csv path/to/file.html
```

The tool creates a backup before applying changes and validates all corrections.

## Features

âœ… Extracts text-only content (no empty components)  
âœ… AI-powered categorization and analysis  
âœ… **Automatic issue detection:**
  - Honorifics (Mr., Mrs., Dr., etc.)
  - Lorem ipsum and placeholder text (TODO, TBD)
  - Spelling errors
  - Long button/navigation text (>3 words)
  - Plural inconsistencies (app/apps, task/tasks)
  - Capitalization issues  
âœ… **Color-coded Excel with 3 sheets:**
  - Issues Summary (sorted by severity)
  - Full Content (complete analysis)
  - Color Legend (workflow guide)  
âœ… Timestamped outputs (never overwrites previous runs)  
âœ… Custom grounding instructions for domain-specific analysis  
âœ… CSV and JSON export for data processing  
âœ… Rate limiting for API protection  
âœ… Progress tracking during analysis  
âœ… **HTML scraping and correction workflow** (optional)  
âœ… **AI Foundry agent integration** (optional)  

## Cost Considerations

- **Figma API**: Free for personal use
- **Azure OpenAI**: Charged per token
  - ~500-1000 tokens per text string analyzed
  - 104 strings â‰ˆ 50K-100K tokens â‰ˆ $0.50-$1.00 (GPT-4o pricing)

## ğŸ”’ Security for Public Repositories

This repository is designed to be **safe for public use**. Here's how we protect your credentials:

### âœ… What's Protected

1. **Environment Variables**
   - All sensitive data (API keys, tokens) stored in `.env` file
   - `.env` is in `.gitignore` and never committed to git
   - `.env.example` template provided without real credentials

2. **Secret Scanning**
   - GitHub Secret Scanning automatically detects leaked credentials
   - Enable in Settings â†’ Code security and analysis â†’ Secret scanning
   - Enable Push Protection to block commits containing secrets

3. **Output Files**
   - Generated reports in `output/` folder may contain sensitive content
   - Add to `.gitignore` if they contain confidential information
   - Review files before committing

### âš ï¸ Important Security Practices

**Before Making Public:**
- âœ… Verify `.env` is in `.gitignore`
- âœ… Check no secrets in commit history: `git log -p | grep -i "api_key\|token\|password"`
- âœ… Enable GitHub Secret Scanning and Push Protection
- âœ… Review all output files before committing

**If You Accidentally Commit a Secret:**
1. **Immediately rotate/revoke** the compromised credential
2. Remove from git history:
   ```bash
   # Use BFG Repo-Cleaner or git filter-repo
   git filter-repo --path .env --invert-paths
   git push --force
   ```
3. Never reuse the exposed credential

**Best Practices:**
- Use separate dev/prod credentials
- Rotate tokens regularly
- Monitor Azure OpenAI usage for anomalies
- Review Figma access token permissions
- Never paste credentials in issues, PRs, or chat

### ğŸ›¡ï¸ Additional Protections

The project includes:
- `.gitignore` configured for sensitive files
- Environment variable validation
- No hardcoded credentials in source code
- Secure credential storage documentation

For questions about security, open an issue (without revealing credentials).

## Contributing

Issues and pull requests welcome! This tool is particularly useful for:
- UX writers auditing content
- Design teams ensuring consistency
- Accessibility teams checking clarity
- Localization teams preparing for translation

## License

MIT

---

**Built with:** Node.js, Figma API, Azure OpenAI, and â˜•
